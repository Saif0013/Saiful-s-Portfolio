{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE5ML Lab 8: Convolutional Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Developing simple CNN\n",
    "\n",
    "When we build a Convolutional Neural Network model, we would need to have convolutional layers, max pooling and dense layers. To enhance the performance, we would also include dropouts. Bellow is a Simple CNN model for the CIFAR-10 Dataset.\n",
    "\n",
    "Dropout is a regularization method proposed by Srivastava, et al at 2014. It is a  simple yet effective way to Prevent Neural Networks from Overfitting. Dropout randomly selectes percentage of neurons and ignore them during training. This means that their contribution to the activation is temporally removed on the forward pass, and any weight updates are not applied to the neuron on the backward pass.\n",
    "\n",
    "### Load dataset and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data() # notice the first line of importing packages\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "# Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "\n",
    "# Encode the outputs with one hot coding\n",
    "Labels = np_utils.to_categorical(Labels) #Converts a class vector (integers) to binary class matrix.\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a convolutional neural networks model\n",
    "\n",
    "More information about parameters settings in Conv2D can be found here: https://keras.io/api/layers/convolution_layers/convolution2d/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py37tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\py37tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), padding='same', activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same', kernel_constraint=maxnorm(3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model\n",
    "define loss function, optimizer and addtional evaluation metrics\n",
    "\n",
    "#### Some addtional information about optimizers\n",
    "\n",
    "To undrestand the concept of optimizers one usually begins with the most basic and popular one, Gradient Descent (used in the bellow example). The important part of the Gradient Descent algorithm (and optimizers in general) is to understand gradients, which indicates: what a small change in a a given parameter (here weight) would do to the loss function. Gradients are a measure of change. They are the connection between the loss function and the weights. In a simple language, they tell us what specific operation should be performed to the weights (ezamples: add 2.1, subtract .07, etc.), for the purpose of reducing the loss (which will increase the accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "lrate = 0.002\n",
    "epochs = 5\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.7, decay=decay, nesterov=False) #Stochastic gradient descent optimizer\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the model\n",
    "it can help us understand model structure, the shape of output and the number of parameters in a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 4,210,090\n",
      "Trainable params: 4,210,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 1.4752 - accuracy: 0.4803 - val_loss: 1.4390 - val_accuracy: 0.4929\n",
      "Epoch 2/5\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 1.4386 - accuracy: 0.4919 - val_loss: 1.4030 - val_accuracy: 0.5038\n",
      "Epoch 3/5\n",
      "50000/50000 [==============================] - 74s 1ms/step - loss: 1.4110 - accuracy: 0.5028 - val_loss: 1.3806 - val_accuracy: 0.5134\n",
      "Epoch 4/5\n",
      "50000/50000 [==============================] - 75s 1ms/step - loss: 1.3820 - accuracy: 0.5102 - val_loss: 1.3606 - val_accuracy: 0.5239\n",
      "Epoch 5/5\n",
      "50000/50000 [==============================] - 76s 2ms/step - loss: 1.3629 - accuracy: 0.5193 - val_loss: 1.3388 - val_accuracy: 0.5302\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1de0ac59408>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 5\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=60, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the trained model with testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 48.97%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deeper CNN network and optimization\n",
    "We can add more layers to have a more complex model. Bellow is an example of a deeper CNN model for the CIFAR-10 Dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              2098176   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,915,114\n",
      "Trainable params: 2,915,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 2.2468 - accuracy: 0.1597 - val_loss: 2.0799 - val_accuracy: 0.2473\n",
      "Epoch 2/20\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.8660 - accuracy: 0.3246 - val_loss: 1.6756 - val_accuracy: 0.4006\n",
      "Epoch 3/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 1.6178 - accuracy: 0.4182 - val_loss: 1.5119 - val_accuracy: 0.4543\n",
      "Epoch 4/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 1.4800 - accuracy: 0.4687 - val_loss: 1.4147 - val_accuracy: 0.4974\n",
      "Epoch 5/20\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.3976 - accuracy: 0.5003 - val_loss: 1.3199 - val_accuracy: 0.5296\n",
      "Epoch 6/20\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.3162 - accuracy: 0.5308 - val_loss: 1.2955 - val_accuracy: 0.5404\n",
      "Epoch 7/20\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 1.2502 - accuracy: 0.5551 - val_loss: 1.2663 - val_accuracy: 0.5492\n",
      "Epoch 8/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 1.1859 - accuracy: 0.5775 - val_loss: 1.1767 - val_accuracy: 0.5794\n",
      "Epoch 9/20\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 1.1253 - accuracy: 0.5997 - val_loss: 1.1837 - val_accuracy: 0.5799\n",
      "Epoch 10/20\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 1.0742 - accuracy: 0.6167 - val_loss: 1.1275 - val_accuracy: 0.5963\n",
      "Epoch 11/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 1.0171 - accuracy: 0.6433 - val_loss: 1.0860 - val_accuracy: 0.6179\n",
      "Epoch 12/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.9672 - accuracy: 0.6614 - val_loss: 1.0810 - val_accuracy: 0.6218\n",
      "Epoch 13/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.9211 - accuracy: 0.6767 - val_loss: 1.0451 - val_accuracy: 0.6381\n",
      "Epoch 14/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.8713 - accuracy: 0.6941 - val_loss: 1.0305 - val_accuracy: 0.6398\n",
      "Epoch 15/20\n",
      "50000/50000 [==============================] - 159s 3ms/step - loss: 0.8281 - accuracy: 0.7095 - val_loss: 1.0018 - val_accuracy: 0.6486\n",
      "Epoch 16/20\n",
      "50000/50000 [==============================] - 145s 3ms/step - loss: 0.7835 - accuracy: 0.7271 - val_loss: 1.0181 - val_accuracy: 0.6446\n",
      "Epoch 17/20\n",
      "50000/50000 [==============================] - 134s 3ms/step - loss: 0.7280 - accuracy: 0.7470 - val_loss: 1.0177 - val_accuracy: 0.6539\n",
      "Epoch 18/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.6872 - accuracy: 0.7583 - val_loss: 1.0054 - val_accuracy: 0.6596\n",
      "Epoch 19/20\n",
      "50000/50000 [==============================] - 132s 3ms/step - loss: 0.6379 - accuracy: 0.7743 - val_loss: 1.0813 - val_accuracy: 0.6454\n",
      "Epoch 20/20\n",
      "50000/50000 [==============================] - 133s 3ms/step - loss: 0.5954 - accuracy: 0.7919 - val_loss: 1.0382 - val_accuracy: 0.6659\n",
      "Accuracy: 66.59%\n"
     ]
    }
   ],
   "source": [
    "# Pakages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "\n",
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data()\n",
    "# normalize inputs (so all pixel values are transformed from [0,255] to [0,0-1.0]\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "# Encode outputs\n",
    "Labels = np_utils.to_categorical(Labels)\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]\n",
    "\n",
    "# Build a deeper CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dense(512, activation='relu', kernel_constraint=maxnorm(3)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "# Compile model\n",
    "epochs = 20\n",
    "lrate = 0.001\n",
    "decay = lrate/epochs\n",
    "sgd = SGD(lr=lrate, momentum=0.9, decay=decay, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])\n",
    "model.summary()\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=64)\n",
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
