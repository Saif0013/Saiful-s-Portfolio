{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "junior-taiwan",
   "metadata": {},
   "source": [
    "## CSE5ML_Lab_9A: Some popular network network structures for image classification\n",
    "VGGNet, ResNet, Inception, and Xception are four types popular neural networks that are proven to be effective in image classification tasks. In keras, there are five popular model structures, namely VGG16, VGG19, ResNet50, Inception V3 and Xception; you can train these models from scratch with newly initialized weights, or you can load pretrained model, based on the ImageNet dataset (another popular benchmark dataset in image classification, which is even larger than the CIFAR10 dataset, with a size of 224*224 for each image). Sometimes we find the pretrained model very helpful when the input data is similar and we do not want to use a lot of time to retrain the model from scratch.\n",
    "\n",
    "If you are interested in more information about these models and implementation with Keras, you can check this link: https://www.pyimagesearch.com/2017/03/20/imagenet-vggnet-resnet-inception-xception-keras/\n",
    "\n",
    "Here we use VGG16 as an example. The same steps can be applied in other models.\n",
    "\n",
    "The below attached is the model achitecture for the original VGG16: \n",
    "\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(x)\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(x)\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(x)\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "\n",
    "    # Classification block\n",
    "    x = layers.Flatten(name='flatten')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "    x = layers.Dense(4096, activation='relu', name='fc2')(x)\n",
    "    x = layers.Dense(classes, activation='softmax', name='predictions')(x)\n",
    "\n",
    "### Load dataset and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aquatic-original",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# packages\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "# load data\n",
    "(Inputs, Labels), (Test_Data, Test_Label) = cifar10.load_data() # notice the first line of importing packages\n",
    "\n",
    "# normalize inputs from 0-255 to 0.0-1.0\n",
    "# Neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. As such it is good practice to normalize the pixel values so that each pixel value has a value between 0 and 1.\n",
    "Inputs = Inputs.astype('float32')\n",
    "Test_Data = Test_Data.astype('float32')\n",
    "Inputs = Inputs / 255.0\n",
    "Test_Data = Test_Data / 255.0\n",
    "\n",
    "# Encode the outputs with one hot coding\n",
    "Labels = np_utils.to_categorical(Labels) #Converts a class vector (integers) to binary class matrix.\n",
    "Test_Label = np_utils.to_categorical(Test_Label)\n",
    "num_classes = Test_Label.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "paperback-warning",
   "metadata": {},
   "source": [
    "### Load Model\n",
    "Here I give two ways to load the model structure and train the model on CIFAR10 dataset. First, if you do not care about how much time or resources to use on trainig, you can train the model from scratch with newly intialized weights. Another way is to train the model based some pretrained weights on similar datasets (because it is found that the first few layers trained for different dataset basically do the similar things, and this's the reason we can consider adopt the weights trained from other dataset, and further fine-tune the weights on our dataset). This can accelate training with fewer epochs/iterations. \n",
    "\n",
    "Note: when apply the below codes, you may find your computer resources can not really support you running them, and here I just show you how you can load a pretrained model weights which has been trained on CIFAR10 already, and you can see how this complex neural network structure can improve classification performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model from scratch\n",
    "\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-indiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pretrained model and finetune\n",
    "# Note that we drop the 3 fully-connected layers at the top of the network which mainly act like classifiers to classify the extracted features from the convolutional layers, because we have a new dataset and we want to train a new classifier.\n",
    "\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(32, 32, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "partial-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\melody\\Documents\\anaconda3\\envs\\py37tf\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\melody\\Documents\\anaconda3\\envs\\py37tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               1048832   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                2570      \n",
      "=================================================================\n",
      "Total params: 2,786,890\n",
      "Trainable params: 2,786,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# load pretrained model which has been finetuned on CIFAR10, not that this model has only used the first 3 blocks in the VGG16 model\n",
    "# load vgg model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.engine import Model\n",
    "\n",
    "# load the model\n",
    "model = VGG16(weights=None, include_top=False, input_shape=(32, 32, 3))\n",
    "# Extract the last layer from third block of vgg16 model\n",
    "last = model.get_layer('block3_pool').output\n",
    "# Add classification layers on top of it\n",
    "x = Flatten()(last)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "pred = Dense(10, activation='softmax')(x)\n",
    "model = Model(model.input, pred)\n",
    "\n",
    "# load pretrained weigths\n",
    "model.load_weights('cifar10-vgg16_model.h5')\n",
    "\n",
    "# summarize the model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "allied-oakland",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "rough-reality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loose-pharmacology",
   "metadata": {},
   "source": [
    "### Train the model\n",
    "You do not need to run this if you just want to evaluate a pretrained model and you not want to train or fine-tune a model, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innovative-honey",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)\n",
    "\n",
    "epochs = 10\n",
    "# Fit the model\n",
    "model.fit(Inputs, Labels, validation_data=(Test_Data, Test_Label), epochs=epochs, batch_size=32, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chinese-sampling",
   "metadata": {},
   "source": [
    "you can save the model weight to use it next time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "several-singapore",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('cifar10_vgg16_new_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-toronto",
   "metadata": {},
   "source": [
    "### Evaluate the model with testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "liked-holly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\melody\\Documents\\anaconda3\\envs\\py37tf\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Accuracy: 86.40%\n"
     ]
    }
   ],
   "source": [
    "# Final evaluation of the model\n",
    "scores = model.evaluate(Test_Data, Test_Label, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-freedom",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
